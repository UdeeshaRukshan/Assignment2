{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "341d39b6-5b91-4b50-a0d1-683da6c40c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.24-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (4.8 kB)\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-1.0.7-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.9 kB)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.55 (from langchain)\n",
      "  Downloading langchain_core-0.3.56-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.37-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /opt/anaconda3/lib/python3.12/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from faiss-cpu) (24.1)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Using cached build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.6-cp312-cp312-macosx_11_0_arm64.whl.metadata (252 bytes)\n",
      "Collecting fastapi==0.115.9 (from chromadb)\n",
      "  Downloading fastapi-0.115.9-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-4.0.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (4.11.0)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.21.1-cp312-cp312-macosx_13_0_universal2.whl.metadata (4.5 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Using cached PyPika-0.48.9-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (4.66.5)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (7.4.0)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-macosx_10_14_universal2.whl.metadata (3.8 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-macosx_10_12_universal2.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (0.9.0)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (8.2.3)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (16 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb)\n",
      "  Downloading orjson-3.10.16-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (0.27.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (13.7.1)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from chromadb) (4.23.0)\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.9->chromadb)\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.7.0-cp312-none-macosx_11_0_arm64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (10.4.0)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (4.2.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (1.0.2)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb) (0.10.6)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading google_auth-2.39.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /opt/anaconda3/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.3)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.2)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.1)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-5.29.4-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Using cached asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich>=10.11.0->chromadb) (2.15.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvloop-0.21.0-cp312-cp312-macosx_10_13_universal2.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-1.0.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.12/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "Downloading langchain-0.3.24-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading faiss_cpu-1.11.0-cp312-cp312-macosx_14_0_arm64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading chromadb-1.0.7-cp39-abi3-macosx_11_0_arm64.whl (16.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp312-cp312-macosx_11_0_arm64.whl (185 kB)\n",
      "Downloading fastapi-0.115.9-py3-none-any.whl (94 kB)\n",
      "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Downloading bcrypt-4.3.0-cp39-abi3-macosx_10_12_universal2.whl (498 kB)\n",
      "Using cached build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-macosx_10_14_universal2.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.56-py3-none-any.whl (437 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.3.37-py3-none-any.whl (359 kB)\n",
      "Downloading mmh3-5.1.0-cp312-cp312-macosx_11_0_arm64.whl (40 kB)\n",
      "Downloading onnxruntime-1.21.1-cp312-cp312-macosx_13_0_universal2.whl (33.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m33.7/33.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.32.1-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.32.1-py3-none-any.whl (55 kB)\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl (12 kB)\n",
      "Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl (30 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl (188 kB)\n",
      "Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl (7.3 kB)\n",
      "Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl (118 kB)\n",
      "Downloading orjson-3.10.16-cp312-cp312-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (249 kB)\n",
      "Downloading posthog-4.0.0-py2.py3-none-any.whl (92 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.7.0-cp312-none-macosx_11_0_arm64.whl (68.6 MB)\n",
      "\u001b[2K   \u001b[91mâ”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/68.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:23\u001b[0m^C\n",
      "\u001b[2K   \u001b[91mâ”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/68.6 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:23\u001b[0m\n",
      "\u001b[?25h^C\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain faiss-cpu chromadb sentence-transformers\n",
    "!pip install ollama\n",
    "!pip install langchain chromadb sentence-transformers ollama\n",
    "!pip list | grep langchain\n",
    "!pip install --upgrade langchain-ollama langchain langchain-community\n",
    "!pip install -U langchain-huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8af5b035-7077-489d-a4e8-7fddc9472ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 21:33:32,294 INFO Python    : 3.12.7\n",
      "2025-05-11 21:33:32,295 INFO LangChain : 0.3.24\n",
      "2025-05-11 21:33:32,296 INFO Found 13 PDF(s) to load.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bd26e5bcf04eb5b2addc17013b0456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading PDFs:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-11 21:33:35,041 INFO Total pages loaded: 369\n",
      "2025-05-11 21:33:35,051 INFO Split into 790 chunks (size=200, overlap=50)\n",
      "2025-05-11 21:33:39,028 INFO Use pytorch device_name: mps\n",
      "2025-05-11 21:33:39,028 INFO Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "2025-05-11 21:33:42,737 INFO Creating new Chroma store & embeddingâ€¦\n",
      "2025-05-11 21:33:43,181 INFO Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "/var/folders/sr/457vz_d97jncjdtsckn4t0bm0000gn/T/ipykernel_34447/3797620754.py:81: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n",
      "2025-05-11 21:33:47,905 INFO Chroma contains ~790 vectors\n",
      "2025-05-11 21:33:47,907 INFO RetrievalQA chain ready.\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 1. Ingest PDFs, Embed & Build RetrievalQA (with forced-rebuild support)\n",
    "\n",
    "# %%\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from shutil import rmtree\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# â€”â€”â€” Logging & Debug Info â€”â€”â€”\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\n",
    "logging.info(f\"Python    : {sys.version.split()[0]}\")\n",
    "try:\n",
    "    import langchain\n",
    "    logging.info(f\"LangChain : {langchain.__version__}\")\n",
    "except ImportError:\n",
    "    logging.warning(\"LangChain not installed or version unknown\")\n",
    "\n",
    "# â€”â€”â€” Configuration â€”â€”â€”\n",
    "PDF_DIR          = Path(\"./\")\n",
    "CHROMA_DIR       = Path(\"./chroma_db_sha\")\n",
    "CHUNK_SIZE       = 200\n",
    "CHUNK_OVERLAP    = 50\n",
    "EMBED_MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "LLM_MODEL        = \"deepseek-r1:1.5b-qwen-distill-q4_K_M\"\n",
    "RETRIEVE_K       = 4\n",
    "\n",
    "# %% \n",
    "def ingest_and_build(rerun: bool = False):\n",
    "    \"\"\"\n",
    "    1) Loads all PDFs in PDF_DIR\n",
    "    2) Splits into chunks\n",
    "    3) Embeds with HuggingFace\n",
    "    4) Persists or reloads Chroma vector store,\n",
    "       optionally wiping it on rerun=True\n",
    "    5) Returns a RetrievalQA chain ready for use\n",
    "    \"\"\"\n",
    "    # 1) Find all PDF files\n",
    "    pdf_files = sorted(PDF_DIR.glob(\"*.pdf\"))\n",
    "    if not pdf_files:\n",
    "        raise FileNotFoundError(f\"No PDFs found in {PDF_DIR.resolve()!s}\")\n",
    "    logging.info(f\"Found {len(pdf_files)} PDF(s) to load.\")\n",
    "\n",
    "    # 2) Load pages\n",
    "    documents = []\n",
    "    for pdf in tqdm(pdf_files, desc=\"Loading PDFs\"):\n",
    "        loader = PyPDFLoader(str(pdf))\n",
    "        documents.extend(loader.load())\n",
    "    logging.info(f\"Total pages loaded: {len(documents)}\")\n",
    "\n",
    "    # 3) Split into chunks\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP\n",
    "    )\n",
    "    chunks = splitter.split_documents(documents)\n",
    "    logging.info(f\"Split into {len(chunks)} chunks (size={CHUNK_SIZE}, overlap={CHUNK_OVERLAP})\")\n",
    "\n",
    "    # 4) Embed + Chroma\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=EMBED_MODEL_NAME)\n",
    "\n",
    "    # â€” if rerun, delete any existing DB so we start fresh\n",
    "    if rerun and CHROMA_DIR.exists():\n",
    "        logging.info(f\"Removing old Chroma directory at {CHROMA_DIR!s}\")\n",
    "        rmtree(CHROMA_DIR)\n",
    "\n",
    "    if rerun or not CHROMA_DIR.exists():\n",
    "        logging.info(\"Creating new Chroma store & embeddingâ€¦\")\n",
    "        db = Chroma.from_documents(\n",
    "            chunks,\n",
    "            embedding=embeddings,\n",
    "            persist_directory=str(CHROMA_DIR),\n",
    "        )\n",
    "        db.persist()\n",
    "    else:\n",
    "        logging.info(\"Loading existing Chroma store.\")\n",
    "        db = Chroma(\n",
    "            persist_directory=str(CHROMA_DIR),\n",
    "            embedding_function=embeddings\n",
    "        )\n",
    "\n",
    "    # count may be approximate\n",
    "    try:\n",
    "        count = db._collection.count()\n",
    "    except Exception:\n",
    "        count = \"unknown\"\n",
    "    logging.info(f\"Chroma contains ~{count} vectors\")\n",
    "\n",
    "    # 5) Build RetrievalQA\n",
    "    retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": RETRIEVE_K})\n",
    "    llm       = Ollama(model=LLM_MODEL, temperature=0.1)\n",
    "    qa_chain  = RetrievalQA.from_chain_type(\n",
    "        llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True\n",
    "    )\n",
    "    logging.info(\"RetrievalQA chain ready.\")\n",
    "    return qa_chain\n",
    "\n",
    "# %%\n",
    "# Usage example:\n",
    "# Set rerun=True to force deletion of old DB and full re-embed.\n",
    "qa = ingest_and_build(rerun=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50e97f3-d6ed-4cf8-87f9-9d5a52a673cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Q:** what are the main compontn of cloud computing\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background:#f5f5f5;padding:10px;border-left:5px solid #999;margin:10px 0;\">\n",
       "          <strong>ğŸ¤” Reasoning:</strong><br>\n",
       "          <br>Okay, so I need to figure out the main components of cloud computing. Let me start by recalling what I know about cloud computing from the provided context.<br><br>First, the context mentions that Cloud Computing involves CSP (Cloud Service Provider) managing infrastructure with hardware, software, networking, and physical security. It also talks about customer responsibility, which is &quot;Security in the Cloud,&quot; where customers manage their data and applications. Additionally, it discusses how multiple cloud service requests are sent to consume excessive memory and processing resources.<br><br>Now, thinking about the main components of cloud computing, I remember that they typically include hardware, software, networking, storage, and security. The context specifically mentions hardware, software, networking, and physical security as part of CSP&#x27;s responsibilities. It also touches on customer responsibility related to data management, which is a key aspect.<br><br>Putting it all together, the main components are hardware, software, networking, storage, and security. These elements work together to provide scalable and secure computing resources for businesses.<br>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"background:#e6f7ff;padding:15px;border-left:5px solid #1890ff;margin:10px 0;\">\n",
       "          <strong>âœ… Final Answer:</strong><br>\n",
       "          The main components of cloud computing include hardware, software, networking, storage, and security. These elements enable businesses to access and manage computational resources efficiently across various applications and services.\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### ğŸ“š Sources"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Doc 1** (page 1): â€œCloud.&quot; CSP is in charge of the infrastructure, including hardware,  software, networking, and physical security. â€¢ Customer Responsibility: Termed &quot;Security in the Cloud.&quot; Customersâ€¦â€"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Doc 2** (page 1): â€œcustomers are responsible for managing their data and applications. â€¢ Cloud Service Provider (CSP) Responsibility: Known as &quot;Security of theâ€¦â€"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Doc 3** (page 21): â€œcripple its performance. â€¢ Multiple cloud service requests are sent, each of which is designed to consume excessive memory and processing resources.â€¦â€"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "- **Doc 4** (page 6): â€œReference: Above the Clouds: A Berkeley View of Cloud Computing, 2009. Resource Provisioningâ€¦â€"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import html\n",
    "import time\n",
    "from IPython.display import display, Markdown, HTML, clear_output\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "# â€”â€”â€” 1) Build the LLM Instance â€”â€”â€”\n",
    "llm = Ollama(model=\"deepseek-r1:1.5b-qwen-distill-q4_K_M\", temperature=0.1)\n",
    "\n",
    "# â€”â€”â€” 2) Define System + User Prompt â€”â€”â€”\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are a helpful AI assistant. Use ONLY the provided context to answer the user's question. \"\n",
    "    \"If the answer is not in the context, say \\\"I don't know.\\\" Do not hallucinate.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Context:\n",
    "---------------------\n",
    "{context}\n",
    "---------------------\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "<think>\n",
    "Explain how you arrive at the answer using step-by-step reasoning based on the context.\n",
    "</think>\n",
    "\n",
    "Answer:\n",
    "Provide the final concise answer based only on the reasoning above.\n",
    "\"\"\"\n",
    ")\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message, user_message])\n",
    "\n",
    "# â€”â€”â€” 3) Build or rebuild RetrievalQA chain â€”â€”â€”\n",
    "# (Assumes you have an existing retriever instance: `qa.retriever`)\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=qa.retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": chat_prompt},\n",
    ")\n",
    "\n",
    "# â€”â€”â€” 4) Spinner HTML â€”â€”â€”\n",
    "spinner_html = \"\"\"\n",
    "<div style=\"display:flex;align-items:center\">\n",
    "  <div class=\"loader\" style=\"\n",
    "      border: 8px solid #f3f3f3;\n",
    "      border-top: 8px solid #3498db;\n",
    "      border-radius: 50%;\n",
    "      width: 40px;\n",
    "      height: 40px;\n",
    "      animation: spin 1s linear infinite;\n",
    "      margin-right:10px;\n",
    "    \"></div>\n",
    "  <div><b>Thinkingâ€¦</b></div>\n",
    "</div>\n",
    "<style>\n",
    "@keyframes spin {\n",
    "  0%   { transform: rotate(0deg); }\n",
    "  100% { transform: rotate(360deg); }\n",
    "}\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "# â€”â€”â€” 5) Q&A helper with styled separation of reasoning & final answer â€”â€”â€”\n",
    "def answer_question(qa_chain, question: str):\n",
    "    clear_output(wait=True)\n",
    "    display(Markdown(f\"**Q:** {html.escape(question)}\\n\"))\n",
    "\n",
    "    # show spinner\n",
    "    handle = display(HTML(spinner_html), display_id=\"spinner\")\n",
    "    resp = qa_chain.invoke({\"query\": question})\n",
    "    handle.update(HTML(\"\"))\n",
    "\n",
    "    raw = resp[\"result\"]\n",
    "    srcs = resp.get(\"source_documents\", [])\n",
    "\n",
    "    # Parse out <think>...</think> and the text that follows\n",
    "    think_html = \"\"\n",
    "    answer_html = \"\"\n",
    "    if \"<think>\" in raw and \"</think>\" in raw:\n",
    "        _, rest = raw.split(\"<think>\", 1)\n",
    "        think_content, after = rest.split(\"</think>\", 1)\n",
    "        # Styled reasoning block\n",
    "        think_html = f\"\"\"\n",
    "        <div style=\"background:#f5f5f5;padding:10px;border-left:5px solid #999;margin:10px 0;\">\n",
    "          <strong>ğŸ¤” Reasoning:</strong><br>\n",
    "          {html.escape(think_content).replace('\\n','<br>')}\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        # Extract the final answer (strip leading \"Answer:\" if present)\n",
    "        answer_text = after.strip()\n",
    "        if answer_text.lower().startswith(\"answer:\"):\n",
    "            answer_text = answer_text[len(\"answer:\"):].strip()\n",
    "        answer_html = f\"\"\"\n",
    "        <div style=\"background:#e6f7ff;padding:15px;border-left:5px solid #1890ff;margin:10px 0;\">\n",
    "          <strong>âœ… Final Answer:</strong><br>\n",
    "          {html.escape(answer_text).replace('\\n','<br>')}\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    else:\n",
    "        # Fallback: show everything as the answer\n",
    "        answer_html = f\"\"\"\n",
    "        <div style=\"background:#e6f7ff;padding:15px;border-left:5px solid #1890ff;margin:10px 0;\">\n",
    "          <strong>âœ… Answer:</strong><br>\n",
    "          {html.escape(raw).replace('\\n','<br>')}\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "    # Display the blocks\n",
    "    if think_html:\n",
    "        display(HTML(think_html))\n",
    "    display(HTML(answer_html))\n",
    "\n",
    "    # Display sources\n",
    "    if srcs:\n",
    "        display(Markdown(\"### ğŸ“š Sources\"))\n",
    "        for i, doc in enumerate(srcs, 1):\n",
    "            page = doc.metadata.get(\"page\", \"unknown\")\n",
    "            snippet = (\n",
    "                html.escape(doc.page_content[:200]).replace(\"\\n\", \" \")\n",
    "            )\n",
    "            display(\n",
    "                Markdown(\n",
    "                    f\"- **Doc {i}** (page {page}): â€œ{snippet}â€¦â€\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "# â€”â€”â€” 6) CLI Loop â€”â€”â€”\n",
    "print(\"Type questions below (or 'stop' to exit):\")\n",
    "while True:\n",
    "    query = input(\"â–¶ \").strip()\n",
    "    if query.lower() in (\"stop\", \"exit\", \"quit\"):\n",
    "        clear_output(wait=True)\n",
    "        print(\"Goodbye! ğŸ‘‹\")\n",
    "        break\n",
    "    if not query:\n",
    "        continue\n",
    "    answer_question(qa, query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d6770-06cc-4c06-88f7-c809d70d58f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
